## References on Bandits

### Introductions

##### Mediums  
- [x] [Bandits for Recommender System Optimization](https://towardsdatascience.com/bandits-for-recommender-system-optimization-1d702662346e)
- [ ] [Solving multiarmed bandits: A comparison of epsilon-greedy and Thompson sampling](https://towardsdatascience.com/solving-multiarmed-bandits-a-comparison-of-epsilon-greedy-and-thompson-sampling-d97167ca9a50)
- [ ] [A/B testing â€” Is there a better way? An exploration of multi-armed bandits](https://towardsdatascience.com/a-b-testing-is-there-a-better-way-an-exploration-of-multi-armed-bandits-98ca927b357d)
- [ ] [Contextual Bandits and Reinforcement Learning](https://towardsdatascience.com/contextual-bandits-and-reinforcement-learning-6bdfeaece72a)
- [ ] [Multi-armed bandit algorithms](https://medium.com/datadriveninvestor/multi-armed-bandit-algorithms-ae174ecdee25)


##### Blogs
- [ ] [A/B Testing Mastery: From Beginner to Pro in a Blog Post](https://cxl.com/blog/ab-testing-guide/)